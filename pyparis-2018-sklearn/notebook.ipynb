{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A more advanced introduction to scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will draw couple of plots during the tutorial. We activate matplotlib to show the plots inline in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why this tutorial?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` provides state-of-the-art machine learning algorithms. \n",
    "These algorithms, however, cannot be directly used on raw data. Raw data needs to be preprocessed beforehand. Thus, besides machine learning algorithms, `scikit-learn` provides a set of preprocessing methods. Furthermore, `scikit-learn` provides connectors for pipelining these estimators (i.e., transformer, regressor, classifier, clusterer, etc.).\n",
    "\n",
    "In this tutorial, we will present the set of `scikit-learn` functionalities allowing for pipelining estimators, evaluating those pipelines, tuning those pipelines using hyper-parameters optimization, and creating complex preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic use-case: train and test a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first example, we will train and test a classifier on a dataset. We will use this example to recall the API of `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `digits` dataset which is a dataset of hand-written digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X` contains the intensities of the 64 image pixels. For each sample in `X`, we get the ground-truth `y` indicating the digit written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The digit in the image is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAA/5JREFUeJzt3cFRomkUhtGPqU6AFDAETAVC0BA0\nBHMhBAlBUjAECYFJwFlMld5unz5nyYLXAp76q9zcze12W0DHP7/7DwC+lqghRtQQI2qIETXE/PqO\nN91sNsl/qR8Oh9G9l5eXsa3z+Ty29fz8PLZ1vV7HtqbdbrfNZ697UkOMqCFG1BAjaogRNcSIGmJE\nDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCHm\nW87uVE2ewVlrrd1uN7a13W7Htj4+Psa2jsfj2NZaa51Op9G9z3hSQ4yoIUbUECNqiBE1xIgaYkQN\nMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIebH\nn93Z7/djW5NncNZa6+7ubmzr/f19bOv19XVsa/L3sZazO8A3EDXEiBpiRA0xooYYUUOMqCFG1BAj\naogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpifvwt\nre12O7Z1uVzGttaavW81afpz/Nt4UkOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbUECNqiBE1\nxIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCHG2Z3/4Xw+j22VTX5n1+t1bOtP\n4UkNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yo\nIUbUECNqiBE1xIgaYkQNMaKGmB9/dmfyrMp+vx/bmjZ5CmfyczydTmNbfwpPaogRNcSIGmJEDTGi\nhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAj\naogRNcRsbrfb17/pZvP1b/ofdrvd1NR6e3sb21prrcfHx7Gtw+EwtjX5nd3f349tTbvdbpvPXvek\nhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAj\naogRNcSIGmJEDTGihhhRQ4yoIebH39Ka9PDwMLr39PQ0tnW5XMa2jsfj2FaZW1rwlxA1xIgaYkQN\nMaKGGFFDjKghRtQQI2qIETXEiBpiRA0xooYYUUOMqCFG1BAjaogRNcSIGmJEDTGihhhRQ4yoIUbU\nECNqiBE1xHzL2R3g9/GkhhhRQ4yoIUbUECNqiBE1xIgaYkQNMaKGGFFDjKghRtQQI2qIETXEiBpi\nRA0xooYYUUOMqCFG1BAjaogRNcSIGmL+BXOCUu0hYKBYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(8, 8), cmap='gray');\n",
    "plt.axis('off')\n",
    "print('The digit in the image is {}'.format(y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we should evaluate our model by training and testing it on distinct sets of data. `train_test_split` is a utility function to split the data into two independent sets. The `stratify` parameter enforces the classes distribution of the train and test datasets to be the same than the one of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have independent training and testing sets, we can learn a machine learning model using the `fit` method. We will use the `score` method to test this method, relying on the default accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API of `scikit-learn` is consistent across classifiers. Thus, we can easily replace the `LogisticRegression` classifier by a `RandomForestClassifier`. These changes are minimal and only related to the creation of the classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the RandomForestClassifier is 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Do the following exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the breast cancer dataset. Import the functions `load_breast_cancer` from `sklearn.datasets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "X_breast, y_breast = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the dataset to keep 30% of it for testing using `sklearn.model_selection.train_test_split`. Make sure to stratify the data (i.e., use the `stratify` parameter) and set the `random_state` to `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_breast_train, X_breast_test, y_breast_train, y_breast_test = train_test_split(\n",
    "    X_breast, y_breast, stratify=y_breast, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a supervised classifier using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_breast_train, y_breast_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the fitted classifier to predict the classification labels for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_breast_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the balanced accuracy on the testing set. You need to import `balanced_accuracy_score` from `sklearn.metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GradientBoostingClassifier is 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "accuracy = balanced_accuracy_score(y_breast_test, y_pred)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. More advanced use-case: preprocess the data before training and testing a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Standardize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing might be required before learning a model. For instance, a user could be interested in creating hand-crafted features or an algorithm might make some apriori assumptions about the data. \n",
    "\n",
    "In our case, the solver used by the `LogisticRegression` expects the data to be normalized. Thus, we need to standardize the data before training the model. To observe this necessary condition, we will check the number of iterations required to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression required 2048 iterations to be fitted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=5000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MinMaxScaler` transformer is used to normalise the data. This scaler should be applied in the following way: learn (i.e., `fit` method) the statistics on a training set and standardize (i.e., `transform` method) both the training and testing sets. Finally, we will train and test the model and the scaled datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.96\n",
      "LogisticRegression required 187 iterations to be fitted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))\n",
    "print('{} required {} iterations to be fitted'.format(clf.__class__.__name__, clf.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By scaling the data, the convergence of the model happened much faster than with the unscaled data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The wrong preprocessing patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We highlighted how to preprocess and adequately train a machine learning model. It is also interesting to spot what would be the wrong way of preprocessing data. There are two potential mistakes which are easy to make but easy to spot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first pattern is to standardize the data before spliting the full set into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.96\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train_prescaled, X_test_prescaled, y_train_prescaled, y_test_prescaled = train_test_split(\n",
    "    X_scaled, y, stratify=y, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train_prescaled)\n",
    "accuracy = clf.score(X_test_prescaled, y_test_prescaled)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second pattern is to standardize the training and testing sets independently. It comes back to call the `fit` methods on both training and testing sets. Thus, the training and testing sets are standardized differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.96\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_prescaled = scaler.fit_transform(X_train)\n",
    "X_test_prescaled = scaler.fit_transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000, random_state=42)\n",
    "clf.fit(X_train_prescaled, y_train)\n",
    "accuracy = clf.score(X_test_prescaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Keep it simple, stupid: use the pipeline connector from `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two previous patterns are an issue with data leaking. However, this is difficult to prevent such a mistake when one has to do the preprocessing by hand. Thus, `scikit-learn` introduced the `Pipeline` object. It sequentially connects several transformers and a classifier (or a regressor). We can create a pipeline as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                       ('clf', LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this pipeline contains the parameters of both the scaler and the classifier. Sometimes, it can be tedious to give a name to each estimator in the pipeline. `make_pipeline` will give a name automatically to each estimator which is the lower case of the class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto', random_state=42, max_iter=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline will have an identical API. We use `fit` to train the classifier and `score` to check the accuracy. However, calling `fit` will call the method `fit_transform` of all transformers in the pipeline. Calling `score` (or `predict` and `predict_proba`) will call internally `transform` of all transformers in the pipeline. It corresponds to the normalization procedure in Sect. 2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.96\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check all the parameters of the pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 1000,\n",
       " 'logisticregression__multi_class': 'auto',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': 42,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False,\n",
       " 'memory': None,\n",
       " 'minmaxscaler': MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       " 'minmaxscaler__copy': True,\n",
       " 'minmaxscaler__feature_range': (0, 1),\n",
       " 'steps': [('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                      multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                      random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Reuse the breast dataset of the first exercise to train a `SGDClassifier` which you can import from `linear_model`. Make a pipeline with this classifier and a `StandardScaler` transformer imported from `sklearn.preprocessing`. Train and test this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "pipe.fit(X_breast_train, y_breast_train)\n",
    "y_pred = pipe.predict(X_breast_test)\n",
    "accuracy = balanced_accuracy_score(y_breast_test, y_pred)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. When more is better than less: cross-validation instead of single split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data is necessary to evaluate the statistical model performance. However, it reduces the number of samples which can be used to learn the model. Therefore, one should use cross-validation whenever possible. Having multiple splits will give information about the model stability as well. \n",
    "\n",
    "`scikit-learn` provides three functions: `cross_val_score`, `cross_val_predict`, and [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html). The latter provides more information regarding fitting time, training and testing scores. I can also return multiple scores at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='lbfgs', multi_class='auto',\n",
    "                                        max_iter=1000, random_state=42))\n",
    "scores = cross_validate(pipe, X, y, cv=3, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cross-validate function, we can quickly check the training and testing scores and make a quick plot using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.199714</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.925249</td>\n",
       "      <td>0.988285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.185093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.943239</td>\n",
       "      <td>0.984975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.179877</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>0.924497</td>\n",
       "      <td>0.993339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.199714    0.001030    0.925249     0.988285\n",
       "1  0.185093    0.000000    0.943239     0.984975\n",
       "2  0.179877    0.010027    0.924497     0.993339"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b93171f080>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD9CAYAAABQvqc9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Use the pipeline of the previous exercise and make a cross-validation instead of a single split evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b9317a76a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD9CAYAAAC85wBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSc3/B2GkiIT2Ti9cAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "scores = cross_validate(pipe, X_breast, y_breast, scoring='balanced_accuracy', cv=3, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyper-parameters optimization: fine-tune the inside of a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you would like to find the parameters of a component of the pipeline which lead to the best accuracy. We already saw that we could check the parameters of a pipeline using `get_params()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'sgdclassifier': SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "               max_iter=1000, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
       "               penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "               tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'sgdclassifier__alpha': 0.0001,\n",
       " 'sgdclassifier__average': False,\n",
       " 'sgdclassifier__class_weight': None,\n",
       " 'sgdclassifier__early_stopping': False,\n",
       " 'sgdclassifier__epsilon': 0.1,\n",
       " 'sgdclassifier__eta0': 0.0,\n",
       " 'sgdclassifier__fit_intercept': True,\n",
       " 'sgdclassifier__l1_ratio': 0.15,\n",
       " 'sgdclassifier__learning_rate': 'optimal',\n",
       " 'sgdclassifier__loss': 'hinge',\n",
       " 'sgdclassifier__max_iter': 1000,\n",
       " 'sgdclassifier__n_iter': None,\n",
       " 'sgdclassifier__n_iter_no_change': 5,\n",
       " 'sgdclassifier__n_jobs': None,\n",
       " 'sgdclassifier__penalty': 'l2',\n",
       " 'sgdclassifier__power_t': 0.5,\n",
       " 'sgdclassifier__random_state': None,\n",
       " 'sgdclassifier__shuffle': True,\n",
       " 'sgdclassifier__tol': 0.001,\n",
       " 'sgdclassifier__validation_fraction': 0.1,\n",
       " 'sgdclassifier__verbose': 0,\n",
       " 'sgdclassifier__warm_start': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('sgdclassifier',\n",
       "   SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                 early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "                 l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "                 max_iter=1000, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
       "                 penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "                 tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False))]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-parameters can be optimized by an exhaustive search. [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) provides such utility and does a cross-validated grid-search over a parameter grid.\n",
    "\n",
    "Let's give an example in which we would like to optimize the `C` and `penalty` parameters of the `LogisticRegression` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('minmaxscaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0, 1))),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=5000,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=42,\n",
       "                                                           solver='saga',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))]),\n",
       "             iid=False, n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.1, 1.0, 10],\n",
       "                         'logisticregression__penalty': ['l2', 'l1']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto',\n",
    "                                        random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, return_train_score=True, iid=False)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the grid-search object, it finds the best possible parameter combination on the training set (using cross-validation). We can introspect the results of the grid-search by accessing the attribute `cv_results_`. It allows us to check the effect of the parameters on the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>param_logisticregression__penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200647</td>\n",
       "      <td>0.009424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.951542</td>\n",
       "      <td>0.935268</td>\n",
       "      <td>0.941573</td>\n",
       "      <td>0.942794</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>5</td>\n",
       "      <td>0.952968</td>\n",
       "      <td>0.959956</td>\n",
       "      <td>0.952328</td>\n",
       "      <td>0.955084</td>\n",
       "      <td>0.003455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586630</td>\n",
       "      <td>0.162702</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregres...</td>\n",
       "      <td>0.885463</td>\n",
       "      <td>0.908482</td>\n",
       "      <td>0.883146</td>\n",
       "      <td>0.892364</td>\n",
       "      <td>0.011437</td>\n",
       "      <td>6</td>\n",
       "      <td>0.905935</td>\n",
       "      <td>0.902113</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.903496</td>\n",
       "      <td>0.001730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.678686</td>\n",
       "      <td>0.017604</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>0.963545</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985442</td>\n",
       "      <td>0.987764</td>\n",
       "      <td>0.986696</td>\n",
       "      <td>0.986634</td>\n",
       "      <td>0.000949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.857070</td>\n",
       "      <td>0.439157</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 1.0, 'logisticregres...</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>0.950893</td>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.953157</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>4</td>\n",
       "      <td>0.977604</td>\n",
       "      <td>0.977753</td>\n",
       "      <td>0.981153</td>\n",
       "      <td>0.978837</td>\n",
       "      <td>0.001639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.864373</td>\n",
       "      <td>0.170891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.977974</td>\n",
       "      <td>0.962054</td>\n",
       "      <td>0.964045</td>\n",
       "      <td>0.968024</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.297890</td>\n",
       "      <td>0.697427</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregress...</td>\n",
       "      <td>0.973568</td>\n",
       "      <td>0.959821</td>\n",
       "      <td>0.950562</td>\n",
       "      <td>0.961317</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.200647      0.009424         0.000000        0.000000   \n",
       "1       0.586630      0.162702         0.005326        0.004107   \n",
       "2       0.678686      0.017604         0.003332        0.004712   \n",
       "3       2.857070      0.439157         0.000000        0.000000   \n",
       "4       1.864373      0.170891         0.000000        0.000000   \n",
       "5       9.297890      0.697427         0.003332        0.004712   \n",
       "\n",
       "  param_logisticregression__C param_logisticregression__penalty  \\\n",
       "0                         0.1                                l2   \n",
       "1                         0.1                                l1   \n",
       "2                           1                                l2   \n",
       "3                           1                                l1   \n",
       "4                          10                                l2   \n",
       "5                          10                                l1   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'logisticregression__C': 0.1, 'logisticregres...           0.951542   \n",
       "1  {'logisticregression__C': 0.1, 'logisticregres...           0.885463   \n",
       "2  {'logisticregression__C': 1.0, 'logisticregres...           0.977974   \n",
       "3  {'logisticregression__C': 1.0, 'logisticregres...           0.964758   \n",
       "4  {'logisticregression__C': 10, 'logisticregress...           0.977974   \n",
       "5  {'logisticregression__C': 10, 'logisticregress...           0.973568   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.935268           0.941573         0.942794        0.006700   \n",
       "1           0.908482           0.883146         0.892364        0.011437   \n",
       "2           0.955357           0.957303         0.963545        0.010234   \n",
       "3           0.950893           0.943820         0.953157        0.008696   \n",
       "4           0.962054           0.964045         0.968024        0.007082   \n",
       "5           0.959821           0.950562         0.961317        0.009452   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            0.952968            0.959956   \n",
       "1                6            0.905935            0.902113   \n",
       "2                2            0.985442            0.987764   \n",
       "3                4            0.977604            0.977753   \n",
       "4                1            1.000000            1.000000   \n",
       "5                3            1.000000            1.000000   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.952328          0.955084         0.003455  \n",
       "1            0.902439          0.903496         0.001730  \n",
       "2            0.986696          0.986634         0.000949  \n",
       "3            0.981153          0.978837         0.001639  \n",
       "4            1.000000          1.000000         0.000000  \n",
       "5            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grid = pd.DataFrame(grid.cv_results_)\n",
    "df_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the grid-search object is also behaving as an estimator. Once it is fitted, calling `score` will fix the hyper-parameters to the best parameters found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10, 'logisticregression__penalty': 'l2'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides this is possible to call the grid-search as any other classifier to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the GridSearchCV is 0.96\n"
     ]
    }
   ],
   "source": [
    "accuracy = grid.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(grid.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to know, we only make the fitting of the grid-search on a single split. However, as previously stated, we might be interested to make an outer cross-validation to estimate the performance of the model and different sample of data and check the potential variation in performance. Since grid-search is an estimator, we can use it directly within the `cross_validate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.216306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.985774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.139238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946578</td>\n",
       "      <td>0.997496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.833241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0  39.216306         0.0    0.928571     0.985774\n",
       "1  39.139238         0.0    0.946578     0.997496\n",
       "2  38.833241         0.0    0.929530     1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Reuse the previous pipeline for the breast dataset and make a grid-search to evaluate the difference between a `hinge` and `log` loss. Besides, fine-tune the `penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sgdclassifier__loss': 'hinge', 'sgdclassifier__penalty': 'l2'}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD9CAYAAAC85wBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "param_grid = {'sgdclassifier__loss': ['hinge', 'log'],\n",
    "              'sgdclassifier__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, iid=False)\n",
    "scores = cross_validate(grid, X_breast, y_breast, scoring='balanced_accuracy', cv=3, return_train_score=True)\n",
    "df_scores = pd.DataFrame(scores)\n",
    "df_scores[['train_score', 'test_score']].boxplot()\n",
    "grid.fit(X_breast_train, y_breast_train)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary: my scikit-learn pipeline in less than 10 lines of code (skipping the import statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b931803208>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD9CAYAAABQvqc9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(),\n",
    "                     LogisticRegression(solver='saga', multi_class='auto', random_state=42, max_iter=5000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10],\n",
    "              'logisticregression__penalty': ['l2', 'l1']}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=3, n_jobs=-1, iid=False)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Heterogeneous data: when you work with data other than numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we used `scikit-learn` to train model using numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` is a NumPy array of `float` values only. However, datasets can contains mixed types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss. Elisabeth Walton</td>\n",
       "      <td>female</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24160</td>\n",
       "      <td>211.3375</td>\n",
       "      <td>B5</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St Louis, MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Allison, Master. Hudson Trevor</td>\n",
       "      <td>male</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Miss. Helen Loraine</td>\n",
       "      <td>female</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113781</td>\n",
       "      <td>151.5500</td>\n",
       "      <td>C22 C26</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Montreal, PQ / Chesterville, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       1         1                    Allen, Miss. Elisabeth Walton  female   \n",
       "1       1         1                   Allison, Master. Hudson Trevor    male   \n",
       "2       1         0                     Allison, Miss. Helen Loraine  female   \n",
       "3       1         0             Allison, Mr. Hudson Joshua Creighton    male   \n",
       "4       1         0  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  female   \n",
       "\n",
       "       age  sibsp  parch  ticket      fare    cabin embarked boat   body  \\\n",
       "0  29.0000      0      0   24160  211.3375       B5        S    2    NaN   \n",
       "1   0.9167      1      2  113781  151.5500  C22 C26        S   11    NaN   \n",
       "2   2.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "3  30.0000      1      2  113781  151.5500  C22 C26        S  NaN  135.0   \n",
       "4  25.0000      1      2  113781  151.5500  C22 C26        S  NaN    NaN   \n",
       "\n",
       "                         home.dest  \n",
       "0                     St Louis, MO  \n",
       "1  Montreal, PQ / Chesterville, ON  \n",
       "2  Montreal, PQ / Chesterville, ON  \n",
       "3  Montreal, PQ / Chesterville, ON  \n",
       "4  Montreal, PQ / Chesterville, ON  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "data = pd.read_csv(os.path.join('data', 'titanic_openml.csv'), na_values='?')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `titanic` dataset contains both categorical, text, and numeric features. We will use this dataset to predict whether a passenger survived the Titanic or not. \n",
    "\n",
    "Let's split the data into training and testing sets and use the `survived` column as a target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['survived']\n",
    "X = data.drop(columns='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could try a `LogisticRegression` classifier and see how good it is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = LogisticRegression()\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, most of the classifiers are designed to work with numerical data. Therefore, we need to convert the categorical data into numeric features. The simplest way is to one-hot encode each categorical feature with the `OneHotEncoder`. Let's give an example for the `sex` and `embarked` columns. Note that we also encounter some data which are missing. We will use a `SimpleImputer` to replace the missing values with a constant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_encoded = ohe.fit_transform(X_train[['sex', 'embarked']])\n",
    "X_encoded.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, it is possible to encode the categorical features. However, we also want to standardize the numerical features. Thus, we need to split the original data into 2 subgroups and apply a different preprocessing: (i) one-hot encoding for the categorical data and (ii) standard scaling for the numerical data. We also need to handle missing values in both cases. For the categorical column, we replace the missing values by the string `'missing_values'` which will be interpreted as a category on its own. For the numerical data, we will replace the missing data by the mean values of the feature of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_cat = ['sex', 'embarked']\n",
    "col_num = ['age', 'sibsp', 'parch', 'fare']\n",
    "\n",
    "X_train_cat = X_train[col_cat]\n",
    "X_train_num = X_train[col_num]\n",
    "X_test_cat = X_test[col_cat]\n",
    "X_test_num = X_test[col_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder())\n",
    "X_train_cat_enc = scaler_cat.fit_transform(X_train_cat)\n",
    "X_test_cat_enc = scaler_cat.transform(X_test_cat)\n",
    "\n",
    "scaler_num = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler())\n",
    "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler_num.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should apply these transformations on the training and testing sets as we did in Sect. 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "X_train_scaled = sparse.hstack((X_train_cat_enc,\n",
    "                                sparse.csr_matrix(X_train_num_scaled)))\n",
    "X_test_scaled = sparse.hstack((X_test_cat_enc,\n",
    "                               sparse.csr_matrix(X_test_num_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the transformation is done, we can combine the informations which are all numerical now. Finally, we use our `LogisticRegression` classifier as a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the LogisticRegression is 0.79\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "accuracy = clf.score(X_test_scaled, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(clf.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above pattern of first transforming the data and then fitting/scoring the classifier is exactly the one of Sect. 2.1. Therefore, we would like to use a pipeline for such purpose. However, we would also like to have different processing on different columns of our matrix. The `ColumnTransformer` transformer or the `make_column_transformer` function should be used. It is used to automatically apply different pipeline on different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Pipeline is 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(SimpleImputer(), StandardScaler())\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "print('Accuracy score of the {} is {:.2f}'.format(pipe.__class__.__name__, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides, it can also be used in another pipeline. Thus, we will be able to use all `scikit-learn` utilities as `cross_validate` or `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columntransformer': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('pipeline-1',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(copy=True,\n",
       "                                                                 fill_value=None,\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='constant',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('onehotencoder',\n",
       "                                                   OneHotEncoder(categorical_features=None,\n",
       "                                                                 categories=None,\n",
       "                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                 handle_unknown='ignore',\n",
       "                                                                 n_values=None,\n",
       "                                                                 sparse=True))]),\n",
       "                                  ['sex', 'embarked']),\n",
       "                                 ('pipeline-2',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('simpleimputer',\n",
       "                                                   SimpleImputer(copy=True,\n",
       "                                                                 fill_value=None,\n",
       "                                                                 missing_values=nan,\n",
       "                                                                 strategy='mean',\n",
       "                                                                 verbose=0)),\n",
       "                                                  ('standardscaler',\n",
       "                                                   StandardScaler(copy=True,\n",
       "                                                                  with_mean=True,\n",
       "                                                                  with_std=True))]),\n",
       "                                  ['age', 'sibsp', 'parch', 'fare'])]),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__pipeline-1': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "                                strategy='constant', verbose=0)),\n",
       "                 ('onehotencoder',\n",
       "                  OneHotEncoder(categorical_features=None, categories=None,\n",
       "                                dtype=<class 'numpy.float64'>,\n",
       "                                handle_unknown='ignore', n_values=None,\n",
       "                                sparse=True))]),\n",
       " 'columntransformer__pipeline-1__memory': None,\n",
       " 'columntransformer__pipeline-1__onehotencoder': OneHotEncoder(categorical_features=None, categories=None,\n",
       "               dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "               n_values=None, sparse=True),\n",
       " 'columntransformer__pipeline-1__onehotencoder__categorical_features': None,\n",
       " 'columntransformer__pipeline-1__onehotencoder__categories': None,\n",
       " 'columntransformer__pipeline-1__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__pipeline-1__onehotencoder__handle_unknown': 'ignore',\n",
       " 'columntransformer__pipeline-1__onehotencoder__n_values': None,\n",
       " 'columntransformer__pipeline-1__onehotencoder__sparse': True,\n",
       " 'columntransformer__pipeline-1__simpleimputer': SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "               strategy='constant', verbose=0),\n",
       " 'columntransformer__pipeline-1__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-1__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-1__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-1__simpleimputer__strategy': 'constant',\n",
       " 'columntransformer__pipeline-1__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-1__steps': [('simpleimputer',\n",
       "   SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "                 strategy='constant', verbose=0)),\n",
       "  ('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "                 dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "                 n_values=None, sparse=True))],\n",
       " 'columntransformer__pipeline-2': Pipeline(memory=None,\n",
       "          steps=[('simpleimputer',\n",
       "                  SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "                                strategy='mean', verbose=0)),\n",
       "                 ('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True))]),\n",
       " 'columntransformer__pipeline-2__memory': None,\n",
       " 'columntransformer__pipeline-2__simpleimputer': SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "               verbose=0),\n",
       " 'columntransformer__pipeline-2__simpleimputer__copy': True,\n",
       " 'columntransformer__pipeline-2__simpleimputer__fill_value': None,\n",
       " 'columntransformer__pipeline-2__simpleimputer__missing_values': nan,\n",
       " 'columntransformer__pipeline-2__simpleimputer__strategy': 'mean',\n",
       " 'columntransformer__pipeline-2__simpleimputer__verbose': 0,\n",
       " 'columntransformer__pipeline-2__standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'columntransformer__pipeline-2__standardscaler__copy': True,\n",
       " 'columntransformer__pipeline-2__standardscaler__with_mean': True,\n",
       " 'columntransformer__pipeline-2__standardscaler__with_std': True,\n",
       " 'columntransformer__pipeline-2__steps': [('simpleimputer',\n",
       "   SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "                 verbose=0)),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True))],\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('pipeline-1', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "                                  strategy='constant', verbose=0)),\n",
       "                   ('onehotencoder',\n",
       "                    OneHotEncoder(categorical_features=None, categories=None,\n",
       "                                  dtype=<class 'numpy.float64'>,\n",
       "                                  handle_unknown='ignore', n_values=None,\n",
       "                                  sparse=True))]), ['sex', 'embarked']),\n",
       "  ('pipeline-2', Pipeline(memory=None,\n",
       "            steps=[('simpleimputer',\n",
       "                    SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "                                  strategy='mean', verbose=0)),\n",
       "                   ('standardscaler',\n",
       "                    StandardScaler(copy=True, with_mean=True, with_std=True))]), ['age',\n",
       "    'sibsp',\n",
       "    'parch',\n",
       "    'fare'])],\n",
       " 'logisticregression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': None,\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'warn',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'lbfgs',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False,\n",
       " 'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                     transformer_weights=None,\n",
       "                     transformers=[('pipeline-1',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(copy=True,\n",
       "                                                                   fill_value=None,\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='constant',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('onehotencoder',\n",
       "                                                     OneHotEncoder(categorical_features=None,\n",
       "                                                                   categories=None,\n",
       "                                                                   dtype=<class 'numpy.float64'>,\n",
       "                                                                   handle_unknown='ignore',\n",
       "                                                                   n_values=None,\n",
       "                                                                   sparse=True))]),\n",
       "                                    ['sex', 'embarked']),\n",
       "                                   ('pipeline-2',\n",
       "                                    Pipeline(memory=None,\n",
       "                                             steps=[('simpleimputer',\n",
       "                                                     SimpleImputer(copy=True,\n",
       "                                                                   fill_value=None,\n",
       "                                                                   missing_values=nan,\n",
       "                                                                   strategy='mean',\n",
       "                                                                   verbose=0)),\n",
       "                                                    ('standardscaler',\n",
       "                                                     StandardScaler(copy=True,\n",
       "                                                                    with_mean=True,\n",
       "                                                                    with_std=True))]),\n",
       "                                    ['age', 'sibsp', 'parch', 'fare'])])),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                      intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                      multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                      random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                      warm_start=False))]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b9329365f8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD9CAYAAAC85wBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBElS8/8AL+1vDMN6PQ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe_cat = make_pipeline(SimpleImputer(strategy='constant'), OneHotEncoder(handle_unknown='ignore'))\n",
    "pipe_num = make_pipeline(StandardScaler(), SimpleImputer())\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "param_grid = {'columntransformer__pipeline-2__simpleimputer__strategy': ['mean', 'median'],\n",
    "              'logisticregression__C': [0.1, 1.0, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1, iid=False)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, scoring='balanced_accuracy', cv=5, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Do the following exercise:\n",
    "\n",
    "Load the adult dataset located in `./data/adult_openml.csv`. Make your own `ColumnTransformer` preprocessor. Pipeline it with a classifier. Fine tune it and check the prediction accuracy within a cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read the adult dataset located in `./data/adult_openml.csv` using `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data = pd.read_csv(os.path.join('data', 'adult_openml.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split the datasets into a data and a target. The target corresponds to the `class` column. For the data, drop the columns `fnlwgt`, `capitalgain`, and `capitalloss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data['class']\n",
    "X = data.drop(columns=['class', 'fnlwgt', 'capitalgain', 'capitalloss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The target is not encoded. Use the `sklearn.preprocessing.LabelEncoder` to encode the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a list containing the name of the categorical columns. Similarly, do the same for the numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_cat = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "col_num = ['age', 'hoursperweek']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a pipeline to one-hot encode the categorical data. Use the `KBinsDiscretizer` for the numerical data. Import it from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "pipe_cat = OneHotEncoder(handle_unknown='ignore')\n",
    "pipe_num = KBinsDiscretizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a `preprocessor` by using the `make_column_transformer`. You should apply the good pipeline to the good column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "preprocessor = make_column_transformer((pipe_cat, col_cat), (pipe_num, col_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pipeline the preprocessor with a `LogisticRegression` classifier. Subsequently define a grid-search to find the best parameter `C`. Train and test this workflow in a cross-validation scheme using `cross_validate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b9329a1ac8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD9CAYAAAC85wBuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFoFJREFUeJzt3X+w3XV95/Hni/BDKwViwbuaUJK2\nlJXVGsodWsbFzW4Xi7ULdu3UBLXLqpMdAZ3irBrHXURwRpzq4C+qjbs2bqtkKVo3NRFwJUd3KqsJ\nbvgVCsYITcj+0I5YL7ILpO/943xuezi5N/d7bm5y8+P5mPlOzufz/Xw/53NOvue+zvfH+X5TVUiS\ndMx8D0CSdGgwECRJgIEgSWoMBEkSYCBIkhoDQZIEGAiSpMZAkCQBBoIkqTl2vgcwilNPPbWWLFky\n38M4Yjz++OM85znPme9hSHtx3Zxbd9111w+q6rSZ2h1WgbBkyRK2bNky38M4YvR6PZYvXz7fw5D2\n4ro5t5I80qWdu4wkSYCBIElqDARJEmAgSJIaA0GSBBgIkqTGQJAkAQaCJKk5rH6YptElmdVy3mtb\nOvq4hXCEq6pppzPe+aVp50k6+nQKhCQXJXkwyfYkq6eYf0OSrW16KMljA/P2DMxbP1D/2dbnfUk+\nneS4uXlJkqTZmHGXUZIFwI3AhcAuYHOS9VW1bbJNVV010P4twDkDXTxRVcum6PqzwOva488BbwI+\nMfIrkCTNiS5bCOcB26tqR1U9CawDLtlH+5XATTN1WlUbqwG+BSzuMmBJ0oHRJRAWATsHyrta3V6S\nnAEsBe4YqH5Wki1J/nuSV02xzHHA64FbO49akjTnupxlNNVpKtMddVwB3FJVewbqfraqdif5OeCO\nJPdW1XcH5v8B8PWq+m9TPnmyClgFMDY2Rq/X6zBkdeX7qUPRxMSE6+Y86BIIu4DTB8qLgd3TtF0B\nXDFYUVW72787kvToH1/4LkCS9wCnAf9muievqjXAGoDx8fHyGulz6NYNXnNehyTvhzA/uuwy2gyc\nmWRpkuPp/9FfP9woyVnAQuDOgbqFSU5oj08FXgpsa+U3Ab8OrKyqv93fFyJJ2j8zBkJVPQ1cCdwG\nPADcXFX3J7k2ycUDTVcC6+qZJ7G/ENiS5G5gE3D9wNlJnwTGgDvbKalXz8HrkSTNUqdfKlfVRmDj\nUN3VQ+VrpljuG8CLp+nTX0lL0iHEXypLkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJj\nIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkw\nECRJjYEgSQLg2PkegKSjV5KRl6mqAzASQccthCQXJXkwyfYkq6eYf0OSrW16KMljA/P2DMxbP1C/\nNMk3k3wnyX9OcvzcvCRJh4uqmnI6451fmnaeDpwZAyHJAuBG4BXA2cDKJGcPtqmqq6pqWVUtAz4G\nfGFg9hOT86rq4oH6DwA3VNWZwA+BN+7na5Ek7Ycuu4zOA7ZX1Q6AJOuAS4Bt07RfCbxnXx2mv534\nz4BLW9VngGuAT3QYj6bwkvfezo+eeGrk5Zas3tC57cnPPo673/PykZ9D0uGhSyAsAnYOlHcBvzJV\nwyRnAEuBOwaqn5VkC/A0cH1VfRH4GeCxqnp6oM9FI45dA370xFM8fP0rR1qm1+uxfPnyzu1HCQ9J\nh58ugTDVUZ/pduStAG6pqj0DdT9bVbuT/BxwR5J7gb/p2meSVcAqgLGxMXq9XochH51GfW8mJiZG\nXsb3XweL69rB1yUQdgGnD5QXA7unabsCuGKwoqp2t393JOkB5wCfB05JcmzbSpi2z6paA6wBGB8f\nr1G+0R5Vbt0w0rd9GH0LYTbPIc2K69q86HKW0WbgzHZW0PH0/+ivH26U5CxgIXDnQN3CJCe0x6cC\nLwW2Vf9UgU3Ab7em/wr4L/vzQiRJ+2fGQGjf4K8EbgMeAG6uqvuTXJtk8KyhlcC6euZ5YS8EtiS5\nm34AXF9Vkwej3wm8Lcl2+scU/uP+vxxJ0mx1+mFaVW0ENg7VXT1UvmaK5b4BvHiaPnfQP4NJknQI\n8NIVkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJ\nAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJ6HhPZUmarZe893Z+9MRTIy+3ZPWGzm1PfvZx3P2e\nl4/8HHomA0HSAfWjJ57i4etfOdIyvV6P5cuXd24/Snhoeu4ykiQBBoIkqTEQJElAx0BIclGSB5Ns\nT7J6ivk3JNnapoeSPDY0/6Qkjyb5+EDdyiT3Jrknya1JTt3/lyNJmq0ZAyHJAuBG4BXA2cDKJGcP\ntqmqq6pqWVUtAz4GfGGom+uArw30eSzwEeCfVtUvAfcAV+7PC5Ek7Z8uWwjnAdurakdVPQmsAy7Z\nR/uVwE2ThSTnAmPA7QNt0qbnJAlwErB7xLFLkuZQl9NOFwE7B8q7gF+ZqmGSM4ClwB2tfAzwIeD1\nwK9Ntquqp5K8GbgXeBz4DnDFNH2uAlYBjI2N0ev1Ogz56DTqezMxMTHyMr7/mg3XzcNDl0DIFHU1\nTdsVwC1VtaeVLwc2VtXO/oZA6zA5DngzcA6wg/5upncB79vriarWAGsAxsfHa5Rzk48qt24Y6bxt\nGP1c79k8h+S6efjoEgi7gNMHyouZfvfOCp75Tf984IIklwMnAscnmQA+D1BV3wVIcjOw18FqSdLB\n0yUQNgNnJlkKPEr/j/6lw42SnAUsBO6crKuq1w7MvwwYr6rVSV4AnJ3ktKr6PnAh8MD+vJCj3U+/\ncDUv/swsMvUzozwHwGi/OJV0+JgxEKrq6SRXArcBC4BPV9X9Sa4FtlTV+tZ0JbCuqqbbnTTY5+4k\n7wW+nuQp4BHgstm+CMGPH7jeywNI2i+drmVUVRuBjUN1Vw+Vr5mhj7XA2oHyJ4FPdhumJOlA85fK\nkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgDvqXxEmdUPx24d7Ubmko5cBsIRYtRfKUM/QGaz\nnKQjk7uMJEmAgSBJagwESRJgIEiSGgNBkgQYCJKkxtNOJR1Q3s3v8GEgSDqgvJvf4cNAOMIl2ff8\nD0xd3+FOqJKOMB5DOMJV1bTTpk2bpp0n6ehjIEiSAANBktQYCJIkwECQJDWdAiHJRUkeTLI9yV4n\nFCe5IcnWNj2U5LGh+ScleTTJxwfqjk+yprX/yySv3v+XI0marRlPO02yALgRuBDYBWxOsr6qtk22\nqaqrBtq/BThnqJvrgK8N1b0b+D9V9YtJjgGeO7uXIEmaC122EM4DtlfVjqp6ElgHXLKP9iuBmyYL\nSc4FxoDbh9q9AXg/QFX9bVX9YJSBS5LmVpdAWATsHCjvanV7SXIGsBS4o5WPAT4EvH2o3Snt4XVJ\nvp3kT5OMjTh2SdIc6vJL5al+6jrdL5dWALdU1Z5WvhzYWFU7h34xeyywGPiLqnpbkrcBHwRev9eT\nJ6uAVQBjY2P0er0OQ1YXExMTvp86KEZdz2azbrou778ugbALOH2gvBjYPU3bFcAVA+XzgQuSXA6c\nCByfZAJ4F/AT4M9auz8F3jhVh1W1BlgDMD4+XqNc30T7Nur1YqRZuXXDyOvZyOvmLJ5De+sSCJuB\nM5MsBR6l/0f/0uFGSc4CFgJ3TtZV1WsH5l8GjFfV6lb+c2A5/d1LvwZsQ5I0b2YMhKp6OsmVwG3A\nAuDTVXV/kmuBLVW1vjVdCayr7hfCeSfwx0k+DHwf+NejD1+SNFc6Xe20qjYCG4fqrh4qXzNDH2uB\ntQPlR4CXdRumJOlA85fKkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1\nBoIkCTAQJEmNgSBJAgwESVJjIEiSAANBktQYCJIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIA\nA0GS1HQKhCQXJXkwyfYkq6eYf0OSrW16KMljQ/NPSvJoko9Psez6JPfN/iVIkubCsTM1SLIAuBG4\nENgFbE6yvqq2TbapqqsG2r8FOGeom+uAr03R978EJmY3dEnSXOqyhXAesL2qdlTVk8A64JJ9tF8J\n3DRZSHIuMAbcPtgoyYnA24D3jTpoSdLc6xIIi4CdA+VdrW4vSc4AlgJ3tPIxwIeAt0/R/Lo27ycj\njFeSdIDMuMsIyBR1NU3bFcAtVbWnlS8HNlbVzuTvu0myDPiFqroqyZJ9PnmyClgFMDY2Rq/X6zBk\ndTExMeH7qYNi1PVsNuum6/L+6xIIu4DTB8qLgd3TtF0BXDFQPh+4IMnlwInA8UkmgEeAc5M83Mbw\nvCS9qlo+3GFVrQHWAIyPj9fy5Xs10Sz1ej18P3XA3bph5PVs5HVzFs+hvXUJhM3AmUmWAo/S/6N/\n6XCjJGcBC4E7J+uq6rUD8y8Dxqtq8iylT7T6JcCXpgoDSdLBM+MxhKp6GrgSuA14ALi5qu5Pcm2S\niweargTWVdV0u5MkSYewLlsIVNVGYONQ3dVD5Wtm6GMtsHaK+oeBF3UZhyTpwPGXypIkwECQJDUG\ngiQJ6HgMQZL2x5LVG0Zf6Nbuy5z87ONG7197MRAkHVAPX//KkZdZsnrDrJbT/nGXkSQJMBAkSY2B\nIEkCDARJUmMgSJIAA0GS1BgIkiTAQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBA\nkCQ1BoIkCTAQJElNp0BIclGSB5NsT7J6ivk3JNnapoeSPDY0/6Qkjyb5eCv/VJINSf4yyf1Jrp+b\nlyNJmq0Z76mcZAFwI3AhsAvYnGR9VW2bbFNVVw20fwtwzlA31wFfG6r7YFVtSnI88NUkr6iqL8/y\ndUiS9lOXLYTzgO1VtaOqngTWAZfso/1K4KbJQpJzgTHg9sm6qvpJVW1qj58Evg0sHn34kqS50iUQ\nFgE7B8q7Wt1ekpwBLAXuaOVjgA8Bb5+u8ySnAP8C+Gq3IUuSDoQZdxkBmaKupmm7Arilqva08uXA\nxqramezdTZJj6W9NfLSqdkz55MkqYBXA2NgYvV6vw5DVxcTEhO+nDlmumwdfl0DYBZw+UF4M7J6m\n7QrgioHy+cAFSS4HTgSOTzJRVZMHptcA36mqD0/35FW1prVjfHy8li9f3mHI6qLX6+H7qUPSrRtc\nN+dBl0DYDJyZZCnwKP0/+pcON0pyFrAQuHOyrqpeOzD/MmB8MgySvA84GXjTfoxfkjRHZjyGUFVP\nA1cCtwEPADdX1f1Jrk1y8UDTlcC6qppud9LfSbIYeDdwNvDtdrqqwSBJ86jLFgJVtRHYOFR39VD5\nmhn6WAusbY93MfWxCUnSPPGXypIkwECQJDUGgiQJMBAkSY2BIEkCDARJUmMgSJIAA0GS1BgIkiTA\nQJAkNQaCJAkwECRJjYEgSQIMBElSYyBIkgADQZLUGAiSJMBAkCQ1BoIkCTAQJEmNgSBJAgwESVJj\nIEiSAANBktR0CoQkFyV5MMn2JKunmH9Dkq1teijJY0PzT0ryaJKPD9Sdm+Te1udHk2T/X46kw0mS\nKadHPvCb087TgTNjICRZANwIvAI4G1iZ5OzBNlV1VVUtq6plwMeALwx1cx3wtaG6TwCrgDPbdNGs\nXoGkw1ZVTTlt2rRp2nk6cLpsIZwHbK+qHVX1JLAOuGQf7VcCN00WkpwLjAG3D9Q9Hzipqu6s/v/w\nfwJeNYvxS5LmSJdAWATsHCjvanV7SXIGsBS4o5WPAT4EvH2KPnd16VOSdHAc26HNVDvtpttuWwHc\nUlV7WvlyYGNV7Rza99e5zySr6O9aYmxsjF6v12HI6mJiYsL3U4ck18350SUQdgGnD5QXA7unabsC\nuGKgfD5wQZLLgROB45NMAB9p/czYZ1WtAdYAjI+P1/LlyzsMWV30ej18P3Uoct2cH10CYTNwZpKl\nwKP0/+hfOtwoyVnAQuDOybqqeu3A/MuA8apa3co/TvKrwDeB36V/MFqSNE9mPIZQVU8DVwK3AQ8A\nN1fV/UmuTXLxQNOVwLrqfhrAm4H/AGwHvgt8eaSRS5LmVJctBKpqI7BxqO7qofI1M/SxFlg7UN4C\nvKjbMCVJB5q/VJYkAZDD6YceSb4PPDLf4ziCnAr8YL4HIU3BdXNunVFVp83U6LAKBM2tJFuqany+\nxyENc92cH+4ykiQBBoIkqTEQjm5r5nsA0jRcN+eBxxAkSYBbCJKkxkCQNJIkp7Trk81m2d9L8lNz\nPSbNDQPhEDLbD1qSjUlOORBjkqZwCv0rGc/G7wEHLRDaDb7UkYFwaJnygzbTSl1Vv1FVj+2rzcHg\nh++ocT3w8+2Wub+f5O1JNie5J8l7AZI8J8mGJHcnuS/Ja5K8FXgBsCnJpqk6TrIgydq2zL1Jrmr1\nv5Dkv7b+vp3k59P3+wNtX9PaLk+yKcnngHtb3euSfKuN+Q9dV6cx3W3qnA7+RP9udE8AW+lfZXYT\n8DlgW5v/ReAu4H5g1cByD9P/ZecS+hcg/FRrczvw7H0831uBbcA99C9MCP3LlP8R/Q/SPcCrW/3K\nVncf8IGBPiaAa+lftfYfA+fSv13qXfQviPj8+X5fneZ8PV0C3Ncev5z+GUGh/wXzS8DLgFcDnxpY\n5uT278PAqfvo+1zgKwPlU9q/3wR+qz1+Fv2tjFcDXwEW0L8r418BzweWA48DS1v7FwJ/DhzXyn8A\n/O58v4+H4jTvA3Aa+M945gftGSt1q3tu+/fZ7Q/zz7TyYCA8DSxr9TcDr9vH8+0GTmiPJz94HwA+\nPNBmIf1vdX8FnEb/goh3AK9q8wv4nfb4OOAbwGmt/Brg0/P9vjod0PX0g23929qm7cAbgV8EvtfW\npwsGlp0pEBbSv/rxx+jfZ/0Y4KeBXVO0vQF4w0D5j4GL22dn00D9lW1dnxzjg8A18/0+HopTp6ud\nat58q6q+N1B+a5Lfao9PB84E/npome9V1db2+C76H97p3AN8NskX6W99APxz+ve8AKCqfpjkZUCv\nqr4PkOSz9L8FfhHYA3y+NT+L/hVsv9LukLcA+J/dXqoOUwHeX1V/uNeM/v3UfwN4f5Lbq+ramTpr\n69tLgF+nf7Ot36F/3GG6557O40PtPlNV75rp+Y92HkM4tP3dSp1kOf0/1udX1UuA/0F/03nY/xt4\nvId9X+L8lcCN9DfT70pyLP0Pz/CPU/b1wfu/9fe3TA1wf1Uta9OLq+rl+1hWh6cf0//WDv3dgm9I\nciJAkkVJnpfkBcBPqupP6G9F/PIUy+4lyanAMVX1eeDfA79cVX8D7EryqtbmhHam0teB17TjDqfR\n/5LyrSm6/Srw20me15Z/brv/u4YYCIeWfX1YTgZ+WFU/SfIPgV/dnydKcgxwelVtAt5B/4D2ifSP\nO1w50G4h/f23/yTJqe1g3Er6xwmGPQicluT8tuxxSf7R/oxTh56q+mvgL5LcB1xI/zjXnUnuBW6h\nvw6/GPhWkq3Au4H3tcXXAF+e7qAysAjoteXWApPf6l9Pfwv5Hvq7Jf8B8Gf0t3Lvpr8b8x1V9b+m\nGO824N8Bt7flv0L/WIOG+EvlQ0w7M+KX6B9c/t9V9Zut/gT6u2gW0f7w0t8P2kvyMDBO/w/6l6rq\nRW2ZfwucWFPcvCjJcfQPWp9M/5v9n1TV9e2b3uRWwx7gvVX1hSSX0v9wBthYVe9o/UxU1YkD/S4D\nPtr6PZb+8YhPzeFbJOkAMRAkSUDHW2hK0lxL8k3ghKHq11fVvfMxHrmFcFRIciPw0qHqj1TVH83H\neCQdmgwESRLgWUaSpMZAkCQBBoIkqTEQJEmAgSBJav4/kq5lzLl2tCQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression(solver='lbfgs', max_iter=1000))\n",
    "param_grid = {'logisticregression__C': [0.1, 1.0, 10]}\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1, iid=False)\n",
    "scores = pd.DataFrame(cross_validate(grid, X, y, scoring='balanced_accuracy', cv=3, n_jobs=-1, return_train_score=True))\n",
    "scores[['train_score', 'test_score']].boxplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
